{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "comparative-channel",
   "metadata": {},
   "source": [
    "In this notebook, we give an illustration of how our implementations work using contact-primary-school dataset:\n",
    "\n",
    "First, we import all the required libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "advanced-attendance",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import community as community_louvain\n",
    "from functions import *\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.metrics as metrics\n",
    "from sknetwork.clustering import modularity\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "obvious-donna",
   "metadata": {},
   "source": [
    "Import data needed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "union-ocean",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_list = pd.read_csv('data/primary_school/edges.csv')\n",
    "triangle_list = pd.read_csv('data/primary_school/triangles.csv')\n",
    "comm_label = pd.read_csv('data/primary_school/node-labels-contact-primary-school.txt', header = None)\n",
    "comm_label = np.array(comm_label[0])\n",
    "overlap_label = pd.read_csv('data/primary_school/primary_school_overlap.csv',header = None)\n",
    "overlap_label = np.array(overlap_label[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "early-breed",
   "metadata": {},
   "source": [
    "Build the graph skeleton of the simplical complex:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "wooden-fruit",
   "metadata": {},
   "outputs": [],
   "source": [
    "G=nx.Graph()\n",
    "\n",
    "unique_nodes = set()\n",
    "for i in range(len(edge_list)):\n",
    "    u = edge_list.iloc[i][0]\n",
    "    v = edge_list.iloc[i][1]\n",
    "    unique_nodes = unique_nodes | {u, v}\n",
    "unique_nodes = list(unique_nodes)\n",
    "unique_nodes.sort()\n",
    "G.add_nodes_from(unique_nodes)\n",
    "\n",
    "for i in range(len(edge_list)):\n",
    "    u = edge_list.iloc[i][0]\n",
    "    v = edge_list.iloc[i][1]\n",
    "    G.add_edge(u,v)\n",
    "    \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exact-security",
   "metadata": {},
   "source": [
    "Compute the boundary maps and the adjacency matrix of the lifted graph, check the condition for Therorem 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reflected-cooperative",
   "metadata": {},
   "outputs": [],
   "source": [
    "B1 = generate_B1ca(G)\n",
    "B2 = generate_B2ca_cc(G,triangle_list)\n",
    "\n",
    "V = np.vstack((np.identity(len(G.edges)),-np.identity(len(G.edges))))\n",
    "\n",
    "A_l_hat = generate_A_l_hat(B1,V)\n",
    "A_u_hat = generate_A_u_hat(B2,V)\n",
    "A_s_hat = generate_A_s_hat(B1,B2)\n",
    "A_rw_hat = generate_A_rw_hat(A_s_hat, A_l_hat,A_u_hat)\n",
    "\n",
    "if np.sum(A_rw_hat) < np.amax(np.sum(A_rw_hat,axis = 1)):\n",
    "    print(\"assumption violation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "uniform-source",
   "metadata": {},
   "source": [
    "Compute the baseline adjacency matrices C, D, E_1 accordingly. The implementation of dendrogram cutting method S can be found at github.com/bagrow/linkcomm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mounted-italian",
   "metadata": {},
   "outputs": [],
   "source": [
    "C = generate_C(B1)\n",
    "D = generate_D(B1)\n",
    "E1 = generate_E1(B1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "demonstrated-mexican",
   "metadata": {},
   "source": [
    "For each adjacency matrix A_rw_hat, C, D, E1, do the following computations to get link partitioning results and evaluations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "structured-feedback",
   "metadata": {},
   "outputs": [],
   "source": [
    "G_dual = nx.from_numpy_matrix(A_rw_hat)\n",
    "louvain_e = community_louvain.best_partition(G_dual)\n",
    "\n",
    "#evaluation metrics\n",
    "community_quality(comm_label,list(louvain_e.values())[0:len(G.edges)],G)\n",
    "overlap_quality_new(G,overlap_label,list(louvain_e.values())[0:len(G.edges)])\n",
    "community_coverage(G,list(louvain_e.values())[0:len(G.edges)])\n",
    "overlap_coverage(G,list(louvain_e.values())[0:len(G_cc.edges)])\n",
    "modularity(A_rw_hat,np.array(list(louvain_e.values())))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
